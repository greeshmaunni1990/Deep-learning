{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Handwritten Image Classification Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n",
      "11501568/11490434 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Load dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train min', 0)\n",
      "('Train max', 255)\n",
      "('Train mean', 33.318421449829934)\n",
      "('Train std', 78.56748998339798)\n"
     ]
    }
   ],
   "source": [
    "# Summarize Train pixel values\n",
    "print('Train min', train_images.min())\n",
    "print('Train max', train_images.max())\n",
    "print('Train mean', train_images.mean())\n",
    "print('Train std', train_images.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test min', 0)\n",
      "('Test max', 255)\n",
      "('Test mean', 33.791224489795916)\n",
      "('Test std', 79.17246322228644)\n"
     ]
    }
   ],
   "source": [
    "# Summarize Test Pixel values\n",
    "print('Test min', test_images.min())\n",
    "print('Test max', test_images.max())\n",
    "print('Test mean', test_images.mean())\n",
    "print('Test std', test_images.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise pixel value on MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('before reshaping', (60000, 28, 28))\n",
      "('width', 28)\n",
      "('height', 28)\n",
      "('channel', 1)\n",
      "('after reshaping', (60000, 28, 28, 1))\n",
      "('test shape', (10000, 28, 28, 1))\n",
      "train min is 0 and train max is 255\n",
      "test min is 0 and test max is 255\n",
      "('length of train iterator', 938)\n",
      "('length of test iterator', 157)\n",
      "shape of batchX is (64, 28, 28, 1) and min of batchX is 0.0 and max of batchX is 1.0\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# load dataset\n",
    "(train_x, train_y), (test_x, test_y) = mnist.load_data()\n",
    "width, height, channel = train_x.shape[1], train_x.shape[2], 1\n",
    "print('before reshaping', train_x.shape)\n",
    "print('width', width)\n",
    "print('height', height)\n",
    "print('channel', channel)\n",
    "# reshape the channels to  have a single channel\n",
    "train_x = train_x.reshape(train_x.shape[0], width, height, channel)\n",
    "print('after reshaping', train_x.shape)\n",
    "test_x = test_x.reshape(test_x.shape[0], width, height, channel)\n",
    "print('test shape', test_x.shape)\n",
    "\n",
    "# confirm the scale\n",
    "print(\"train min is {} and train max is {}\".format(train_x.min(), train_x.max()))\n",
    "print(\"test min is {} and test max is {}\".format(test_x.min(), test_x.max()))\n",
    "\n",
    "# create a generator to rescale the values in between 0 and 1\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# generate batches ofaugmented data using iterators\n",
    "train_iterator = datagen.flow(train_x, train_y, batch_size=64)\n",
    "test_iterator = datagen.flow(test_x, test_y, batch_size=64)\n",
    "\n",
    "print('length of train iterator', len(train_iterator))\n",
    "print('length of test iterator', len(test_iterator))\n",
    "\n",
    "# check if scling works\n",
    "batchX, batchY = train_iterator.next()\n",
    "print('shape of batchX is {} and min of batchX is {} and max of batchX is {}'.format(batchX.shape, batchX.min(), batchX.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Center Images with ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train per image mean', 33.318421449829934)\n",
      "('test per image mean', 33.791224489795916)\n",
      "('mean of dataset', array([[[33.318447]]], dtype=float32))\n",
      "batchX shape is (64, 28, 28, 1) and batchX mean is 0.192991495132\n",
      "batchX shape after effect on entire dataset is (60000, 28, 28, 1) and batchX mean is -1.95129177882e-05\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load data\n",
    "(train_x, train_y),(test_x, test_y) = mnist.load_data()\n",
    "width, height, channel = train_x.shape[1], train_x.shape[2], 1\n",
    "\n",
    "#reshape to have a single channel\n",
    "train_x = train_x.reshape(train_x.shape[0], width, height, channel)\n",
    "test_x = test_x.reshape(test_x.shape[0], width, height, channel)\n",
    "\n",
    "# per-image mean\n",
    "print(\"train per image mean\", train_x.mean())\n",
    "print('test per image mean', test_x.mean())\n",
    "\n",
    "# Feature-wise will check for the entire dataset\n",
    "datagen = ImageDataGenerator(featurewise_center=True)\n",
    "\n",
    "# calculate the mean on the training datasets\n",
    "datagen.fit(train_x)\n",
    "\n",
    "print('mean of dataset', datagen.mean)\n",
    "\n",
    "# generate the effect on single batch\n",
    "train_iterator = datagen.flow(train_x, train_y, batch_size=64)\n",
    "\n",
    "# get a batch\n",
    "batchX, batchY = train_iterator.next()\n",
    "print('batchX shape is {} and batchX mean is {}'.format(batchX.shape, batchX.mean()))\n",
    "\n",
    "# generate the effect on the entire dataset\n",
    "train_iterator = datagen.flow(train_x, train_y, batch_size=len(train_x), shuffle=False)\n",
    "\n",
    "# get a batch\n",
    "batchX, batchY = train_iterator.next()\n",
    "print('batchX shape after effect on entire dataset is {} and batchX mean is {}'.format(batchX.shape, batchX.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize Image with ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean is 33.3184214498 and train std is 78.5674899834\n",
      "datagen mean is [[[33.79124]]] and datagen std is [[[79.172455]]]\n",
      "batchX shape is (64, 28, 28, 1) and batchX mean is 0.00768111879006 and batchX std is 1.00811982155\n",
      "for entire dataset batchX shape is (60000, 28, 28, 1) and batchX mean is -0.0059720184654 and batchX std is 0.992359101772\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "(train_x, train_y), (test_x, test_y) = mnist.load_data()\n",
    "\n",
    "width, height, channel = train_x.shape[1], train_x.shape[2], 1\n",
    "\n",
    "# reshape train datasets\n",
    "train_x = train_x.reshape(train_x.shape[0], width, height, channel)\n",
    "\n",
    "# reshape test  datasets\n",
    "test_x = test_x.reshape(test_x.shape[0], width, height, channel)\n",
    "\n",
    "print('train mean is {} and train std is {}'.format(train_x.mean(), train_x.std()))\n",
    "\n",
    "# Create generator\n",
    "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "\n",
    "# calculate the mean of training datasets\n",
    "datagen.fit(test_x)\n",
    "\n",
    "print('datagen mean is {} and datagen std is {}'.format(datagen.mean, datagen.std))\n",
    "\n",
    "# generate the effect on single batch\n",
    "train_iterator = datagen.flow(train_x, train_y, batch_size=64)\n",
    "\n",
    "# get a batch\n",
    "batchX, batchY = train_iterator.next()\n",
    "print('batchX shape is {} and batchX mean is {} and batchX std is {}'.format(batchX.shape, batchX.mean(), batchX.std()))\n",
    "\n",
    "# effect on entire dataset\n",
    "train_iterator = datagen.flow(train_x, train_y, batch_size=len(train_x), shuffle=False)\n",
    "batchX, batchY = train_iterator.next()\n",
    "print('for entire dataset batchX shape is {} and batchX mean is {} and batchX std is {}'.format(batchX.shape, batchX.mean(), batchX.std()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
